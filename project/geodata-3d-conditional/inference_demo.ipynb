{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ba292a",
   "metadata": {},
   "source": [
    "## Demonstration of Conditional Inference with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918f9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyvista as pv\n",
    "\n",
    "from geogen.model import GeoModel\n",
    "import geogen.plot as geovis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1934dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc9b04",
   "metadata": {},
   "source": [
    "Set the configuration to match that from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": {\n",
    "        \"name\": \"generative-conditional-3d\",\n",
    "        \"root_dir\": os.getcwd(),\n",
    "    },\n",
    "    # Data loader configurations\n",
    "    \"data\": {\n",
    "        \"shape\": (64, 64, 64),  # [C, X, Y, Z]\n",
    "        \"bounds\": (\n",
    "            (-1920, 1920),\n",
    "            (-1920, 1920),\n",
    "            (-1920, 1920),\n",
    "        ),\n",
    "        \"batch_size\": 8,\n",
    "        \"epoch_size\": 10_000,\n",
    "    },\n",
    "    # Categorical embedding parameters\n",
    "    \"embedding\": {\n",
    "        \"num_categories\": 15,\n",
    "        \"dim\": 15,\n",
    "    },\n",
    "    # Inference parameters\n",
    "    \"inference\": {\n",
    "        \"seed\": None,\n",
    "        \"n_samples\": 1,\n",
    "        \"batch_size\": 4,\n",
    "        \"save_imgs\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1d213",
   "metadata": {},
   "source": [
    "### Generating Conditional Samples\n",
    "The model is trained on surface and borehole data. To generate samples, a random sample of conditinal data should be sampled from the StructuralGeo synthetic geology generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inference_experiments import (\n",
    "    create_cond_data,\n",
    "    save_model_and_boreholes,\n",
    "    load_model_and_boreholes,\n",
    "    show_model_and_boreholes,\n",
    ")\n",
    "\n",
    "\n",
    "def show_model_and_boreholes(model, boreholes):\n",
    "    \"\"\"\n",
    "    Plot the model and boreholes side by side. Two 3D tensor inputs\n",
    "    \"\"\"\n",
    "    # Make two pane pyvista plot\n",
    "    p = pv.Plotter(shape=(1, 2))\n",
    "\n",
    "    # Plot the synthetic model\n",
    "    p.subplot(0, 0)\n",
    "    m = GeoModel.from_tensor(model.squeeze().detach().cpu())\n",
    "    geovis.volview(m, plotter=p, show_bounds=True)\n",
    "\n",
    "    # Select 2nd pane\n",
    "    p.subplot(0, 1)\n",
    "    bh = GeoModel.from_tensor(boreholes.squeeze().detach().cpu())\n",
    "    geovis.volview(bh, plotter=p, show_bounds=True)\n",
    "\n",
    "    p.show()\n",
    "\n",
    "\n",
    "# Generate conditional samples and save to folder\n",
    "save_dir = os.path.join(config[\"project\"][\"root_dir\"], \"samples/jupyter-demo\")\n",
    "cond_data_folder_title = \"cond_generation\"\n",
    "num_samples = 4\n",
    "create_cond_data(save_dir, cond_data_folder_title, device, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c5ac5be9ee4aaaac6f1896ce35e797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25d9c877c20_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and check saved model\n",
    "sample_number = 0\n",
    "samples_dir = os.path.join(save_dir, f\"{cond_data_folder_title}_{sample_number}\")\n",
    "model, boreholes = load_model_and_boreholes(samples_dir)\n",
    "show_model_and_boreholes(model, boreholes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb2d3f",
   "metadata": {},
   "source": [
    "## Conditional Inference\n",
    "From the generated conditional values, the trained inferennce model is used to generate multiple reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying EMA shadow to model...\n"
     ]
    }
   ],
   "source": [
    "from utils import download_if_missing\n",
    "from model_inference_experiments import load_model_with_ema_option\n",
    "\n",
    "relative_checkpoint_path = os.path.join(\"demo_model\", \"conditional-weights.ckpt\")\n",
    "checkpoint_path = os.path.join(config[\"project\"][\"root_dir\"], relative_checkpoint_path)\n",
    "weights_url = \"https://github.com/chipnbits/flowtrain_stochastic_interpolation/releases/download/v1.0.0/conditional-weights.ckpt\"\n",
    "download_if_missing(checkpoint_path, weights_url)\n",
    "\n",
    "flowmatching_model = load_model_with_ema_option(\n",
    "    checkpoint_path, map_location=device, use_ema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40496b",
   "metadata": {},
   "source": [
    "An auto-populating function is provided that \n",
    "\n",
    "1. Iterates through a folder `save_dir` containing subfolders `cond_data_folder_title` with conditional data `boreholes.pt` and `true_model.pt`\n",
    "2. Creates the conditional data that includes surface, air, and boreholes from `boreholes.pt` and `true_model.pt`\n",
    "3. Runs the inference routine on the data to produce `n_samples_each` for each set of conditional data\n",
    "4. Saves the solutions in the same subfolder with `sample_title_000.pt` naming convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba241280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inference_experiments import populate_solutions\n",
    "\n",
    "populate_solutions(\n",
    "    save_dir=save_dir,\n",
    "    cond_data_folder_title=cond_data_folder_title,\n",
    "    device=device,\n",
    "    model=flowmatching_model,\n",
    "    n_samples_each=9,\n",
    "    batch_size=1,\n",
    "    sample_title=\"sample\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460116b",
   "metadata": {},
   "source": [
    "### Loading and Viewing Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10058c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: c:\\Users\\sghys\\ComputationalResearch\\geotraining\\flowtrain_stochastic_interpolation\\project\\geodata-3d-conditional\\samples/jupyter-demo\\cond_generation_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bea074b0bd842538b484ec0c81a72da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25db6071f40_1&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a918bd027a24f18af80e3d9ed98ca5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25d9ccd7e00_2&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_inference_experiments import load_solutions, show_solutions\n",
    "\n",
    "# Same folder as the stored conditional data\n",
    "sample_number = 0\n",
    "samples_dir = os.path.join(save_dir, f\"{cond_data_folder_title}_{sample_number}\")\n",
    "print(\"Loading from:\", samples_dir)\n",
    "# Autoparse the true_model.pt, boreholes.pt, and any solutions\n",
    "geomodel, boreholes = load_model_and_boreholes(samples_dir)\n",
    "solutions = load_solutions(samples_dir, sample_title=\"sample\")\n",
    "show_model_and_boreholes(geomodel, boreholes)\n",
    "show_solutions(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb2e28",
   "metadata": {},
   "source": [
    "### Ensemble Analysis\n",
    "Precomputed models and borehole data is provided by decompression of an archive with the model featured in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tarfile, tempfile, gzip\n",
    "\n",
    "\n",
    "def unpack_pt_archive(archive_path: str, dest_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Decompress a .tar.gz produced by pack_pt_folder into dest_dir,\n",
    "    recreating the original filenames/structure (only .pt files are restored).\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # Stream-decompress gzip to a temp tar for safe random access\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    try:\n",
    "        with gzip.open(archive_path, \"rb\") as gz, open(tmp_path, \"wb\") as out:\n",
    "            while True:\n",
    "                chunk = gz.read(1024 * 1024)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                out.write(chunk)\n",
    "\n",
    "        with tarfile.open(tmp_path, \"r\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "                ad = os.path.abspath(directory)\n",
    "                at = os.path.abspath(target)\n",
    "                return os.path.commonprefix([ad, at]) == ad\n",
    "\n",
    "            for member in tar.getmembers():\n",
    "                if not (member.isfile() and member.name.endswith(\".pt\")):\n",
    "                    continue\n",
    "                target_path = os.path.join(dest_dir, member.name)\n",
    "                if not is_within_directory(dest_dir, target_path):\n",
    "                    raise Exception(\"Unsafe path in archive\")\n",
    "                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                with tar.extractfile(member) as src, open(target_path, \"wb\") as dst:\n",
    "                    dst.write(src.read())\n",
    "    finally:\n",
    "        try:\n",
    "            os.unlink(tmp_path)\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf26df3",
   "metadata": {},
   "source": [
    "Decompress `boreholes.pt`, `true_model.pt`, and solutions into a samples directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "145d861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored to: c:\\Users\\sghys\\ComputationalResearch\\geotraining\\flowtrain_stochastic_interpolation\\project\\geodata-3d-conditional\\samples/jupyter-demo/paper_cond_gen_0\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "rel = \"samples/jupyter-demo/paper_cond_gen_0\"\n",
    "samples_dir = os.path.join(root, rel)\n",
    "archive_path = os.path.join(root, \"dikes_ptpack.tar.gz\")\n",
    "unpack_pt_archive(archive_path, samples_dir)\n",
    "print(\"Restored to:\", samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050986b9",
   "metadata": {},
   "source": [
    "Verify the data loaded and displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3afe5e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192f48a544b7462fbae9e3c7fc006aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25eb64ec050_12&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900262a401e042f4a9a72c6ad32e5d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25eb64ec0b0_13&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_number = 0\n",
    "geomodel, boreholes = load_model_and_boreholes(samples_dir)\n",
    "solutions = load_solutions(samples_dir, sample_title=\"sample\")\n",
    "show_model_and_boreholes(geomodel, boreholes)\n",
    "# Limit to 10 solutions for display\n",
    "show_solutions(solutions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_probabilities(\n",
    "    solutions: torch.Tensor, num_categories: int = 15\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute per-voxel class probabilities by majority vote across the batch.\n",
    "    Input: [B,X,Y,Z] of categories and Output: [C,X,Y,Z] of probabilities\n",
    "    \"\"\"\n",
    "    assert solutions.dim() == 4\n",
    "    B, X, Y, Z = solutions.shape\n",
    "\n",
    "    # Shift labels to 0..C-1 if they are -1..C-2\n",
    "    if solutions.min().item() < 0:\n",
    "        sol_shifted = solutions + 1\n",
    "    else:\n",
    "        sol_shifted = solutions\n",
    "    sol_shifted = sol_shifted.to(torch.long)  # required by bincount\n",
    "\n",
    "    sols_one_hot = (\n",
    "        torch.nn.functional.one_hot(sol_shifted, num_categories)\n",
    "        .permute(0, 4, 1, 2, 3)\n",
    "        .float()\n",
    "    )  # [B, 15, 64, 64, 64]\n",
    "    probability_vector = sols_one_hot.mean(dim=0, keepdim=False)\n",
    "\n",
    "    return probability_vector\n",
    "\n",
    "\n",
    "solution_probabilistic = vote_probabilities(solutions, num_categories=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535270f1",
   "metadata": {},
   "source": [
    "## Display Probabilistic Results\n",
    "The probability for one of the dike categories is compared against the true model and the conditional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ca1f7ad0f74accace09458b9b78eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25ffcad6d20_30&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45d3a2de3f746d5baa6aefa73a27469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:55083/index.html?ui=P_0x25ffcac19a0_31&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_voxel_grid_from_tensor(\n",
    "    data, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=None\n",
    "):\n",
    "    \"\"\" \"\"\"\n",
    "    assert data.ndim == 3, \"Data must be 3D\"\n",
    "    dims = data.shape\n",
    "\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "\n",
    "    # Create a padded grid with n+1 nodes and node spacing equal to model sample spacing\n",
    "    dimensions = tuple(x + 1 for x in dims)\n",
    "    spacing = tuple((x[1] - x[0]) / (r - 1) for x, r in zip(bounds, dims))\n",
    "    # pad origin with a half cell size to center the grid\n",
    "    origin = tuple(x[0] - cs / 2 for x, cs in zip(bounds, spacing))\n",
    "\n",
    "    # Create a structured grid with n+1 nodes in each dimension forming n^3 cells\n",
    "    grid = pv.ImageData(\n",
    "        dimensions=dimensions,\n",
    "        spacing=spacing,\n",
    "        origin=origin,\n",
    "    )\n",
    "    # Necessary to reshape data vector in Fortran order to match the grid\n",
    "    grid[\"values\"] = data.flatten(order=\"F\")\n",
    "    grid = grid.threshold(threshold, all_scalars=True)\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "geomodel.squeeze_().squeeze_()\n",
    "true_grid = get_voxel_grid_from_tensor(\n",
    "    geomodel, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=-0.5\n",
    ")\n",
    "boreholes.squeeze_().squeeze_()\n",
    "borehole_grid = get_voxel_grid_from_tensor(\n",
    "    boreholes, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=-0.5\n",
    ")\n",
    "\n",
    "# Index into the category of choice\n",
    "DIKE_VALS = [6, 7, 8]\n",
    "dike_indices = [x + 1 for x in DIKE_VALS]  # Account for earlier shift\n",
    "dike_probs = solution_probabilistic[dike_indices, :, :, :]  # Slice out only dike layers\n",
    "\n",
    "# Set to spatial coords\n",
    "x = np.linspace(-1920, 1920, 64)\n",
    "y = np.linspace(-1920, 1920, 64)\n",
    "z = np.linspace(-1920, 1920, 64)\n",
    "x, y, z = np.meshgrid(x, y, z, indexing=\"ij\")  # Ensure correct shape order\n",
    "mesh = pv.StructuredGrid(x, y, z)\n",
    "\n",
    "# Extract the first channel\n",
    "dike1_data = dike_probs[1].detach().cpu().numpy().ravel(order=\"F\")\n",
    "mesh[\"dike1\"] = dike1_data  # Assign to mesh\n",
    "\n",
    "dike2_data = dike_probs[2].detach().cpu().numpy().ravel(order=\"F\")\n",
    "mesh[\"dike2\"] = dike2_data  # Assign to mesh\n",
    "\n",
    "dike1_true = true_grid.copy()\n",
    "dike1_true[\"values\"] = np.where(\n",
    "    ~np.isin(dike1_true[\"values\"], DIKE_VALS[1]), -1, dike1_true[\"values\"]\n",
    ")\n",
    "dike1_true = dike1_true.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike2_true = true_grid.copy()\n",
    "dike2_true[\"values\"] = np.where(\n",
    "    ~np.isin(dike2_true[\"values\"], DIKE_VALS[2]), -1, dike2_true[\"values\"]\n",
    ")\n",
    "dike2_true = dike2_true.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike1_samples = borehole_grid.copy()\n",
    "dike1_samples[\"values\"] = np.where(\n",
    "    ~np.isin(dike1_samples[\"values\"], DIKE_VALS[1]), -1, dike1_samples[\"values\"]\n",
    ")\n",
    "dike1_samples = dike1_samples.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike2_samples = borehole_grid.copy()\n",
    "dike2_samples[\"values\"] = np.where(\n",
    "    ~np.isin(dike2_samples[\"values\"], DIKE_VALS[2]), -1, dike2_samples[\"values\"]\n",
    ")\n",
    "dike2_samples = dike2_samples.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(\n",
    "    dike1_true,\n",
    "    color=\"orange\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=0.3,\n",
    ")\n",
    "p.add_mesh(\n",
    "    dike1_samples,\n",
    "    scalars=None,\n",
    "    color=\"red\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=1.0,\n",
    ")\n",
    "p.add_title(\"Dike 1 True with Borehole Samples\")\n",
    "p.show()\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(\n",
    "    dike1_samples,\n",
    "    scalars=None,\n",
    "    color=\"red\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=1.0,\n",
    ")\n",
    "\n",
    "contour = mesh.contour([0.05, 0.3, 0.6, 0.9], scalars=f\"dike1\")\n",
    "p.add_mesh(\n",
    "    contour,\n",
    "    opacity=0.3,\n",
    "    cmap=\"Wistia\",\n",
    "    show_scalar_bar=False,\n",
    ")\n",
    "\n",
    "p.add_scalar_bar(\n",
    "    f\"Probability Contour\",\n",
    "    vertical=False,\n",
    "    title_font_size=24,\n",
    "    label_font_size=24,\n",
    "    fmt=\"%.2f\",\n",
    "    n_labels=4,\n",
    ")\n",
    "\n",
    "p.add_title(\"Dike 1 Probabilistic Surfaces with Borehole Samples\")\n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
