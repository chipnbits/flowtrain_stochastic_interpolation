{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ba292a",
   "metadata": {},
   "source": [
    "## Demonstration of Conditional Inference with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918f9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyvista as pv\n",
    "\n",
    "from geogen.model import GeoModel\n",
    "import geogen.plot as geovis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1934dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc9b04",
   "metadata": {},
   "source": [
    "Set the configuration to match that from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32f9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": {\n",
    "        \"name\": \"generative-conditional-3d\",\n",
    "        \"root_dir\": os.getcwd(),\n",
    "    },\n",
    "    # Data loader configurations\n",
    "    \"data\": {\n",
    "        \"shape\": (64, 64, 64),  # [C, X, Y, Z]\n",
    "        \"bounds\": (\n",
    "            (-1920, 1920),\n",
    "            (-1920, 1920),\n",
    "            (-1920, 1920),\n",
    "        ),\n",
    "        \"batch_size\": 8,\n",
    "        \"epoch_size\": 10_000,\n",
    "    },\n",
    "    # Categorical embedding parameters\n",
    "    \"embedding\": {\n",
    "        \"num_categories\": 15,\n",
    "        \"dim\": 15,\n",
    "    },\n",
    "    # Inference parameters\n",
    "    \"inference\": {\n",
    "        \"seed\": None,\n",
    "        \"n_samples\": 1,\n",
    "        \"batch_size\": 4,\n",
    "        \"save_imgs\": True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1d213",
   "metadata": {},
   "source": [
    "### Generating Conditional Samples\n",
    "The model is trained on surface and borehole data. To generate samples, a random sample of conditinal data should be sampled from the StructuralGeo synthetic geology generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eee2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inference_experiments import (\n",
    "    create_cond_data,\n",
    "    save_model_and_boreholes,\n",
    "    load_model_and_boreholes,\n",
    "    show_model_and_boreholes,\n",
    ")\n",
    "\n",
    "\n",
    "def show_model_and_boreholes(model, boreholes):\n",
    "    \"\"\"\n",
    "    Plot the model and boreholes side by side. Two 3D tensor inputs\n",
    "    \"\"\"\n",
    "    # Make two pane pyvista plot\n",
    "    p = pv.Plotter(shape=(1, 2))\n",
    "\n",
    "    # Plot the synthetic model\n",
    "    p.subplot(0, 0)\n",
    "    m = GeoModel.from_tensor(model.squeeze().detach().cpu())\n",
    "    geovis.volview(m, plotter=p, show_bounds=True)\n",
    "\n",
    "    # Select 2nd pane\n",
    "    p.subplot(0, 1)\n",
    "    bh = GeoModel.from_tensor(boreholes.squeeze().detach().cpu())\n",
    "    geovis.volview(bh, plotter=p, show_bounds=True)\n",
    "\n",
    "    p.show()\n",
    "\n",
    "\n",
    "# Generate conditional samples and save to folder\n",
    "save_dir = os.path.join(config[\"project\"][\"root_dir\"], \"samples/jupyter-demo\")\n",
    "cond_data_folder_title = \"cond_generation\"\n",
    "num_samples = 4\n",
    "create_cond_data(save_dir, cond_data_folder_title, device, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b795774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8261b149204a60a37db193813dc6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36623/index.html?ui=P_0x7d484a41c1a0_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and check saved model\n",
    "sample_number = 0\n",
    "samples_dir = os.path.join(save_dir, f\"{cond_data_folder_title}_{sample_number}\")\n",
    "model, boreholes = load_model_and_boreholes(samples_dir)\n",
    "show_model_and_boreholes(model, boreholes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb2d3f",
   "metadata": {},
   "source": [
    "## Conditional Inference\n",
    "From the generated conditional values, the trained inferennce model is used to generate multiple reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15efad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying EMA shadow to model...\n"
     ]
    }
   ],
   "source": [
    "from utils import download_if_missing\n",
    "from model_inference_experiments import load_model_with_ema_option\n",
    "\n",
    "relative_checkpoint_path = os.path.join(\"demo_model\", \"conditional-weights.ckpt\")\n",
    "checkpoint_path = os.path.join(config[\"project\"][\"root_dir\"], relative_checkpoint_path)\n",
    "weights_url = \"https://github.com/chipnbits/flowtrain_stochastic_interpolation/releases/download/v1.0.0/conditional-weights.ckpt\"\n",
    "download_if_missing(checkpoint_path, weights_url)\n",
    "\n",
    "flowmatching_model = load_model_with_ema_option(\n",
    "    checkpoint_path, map_location=device, use_ema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40496b",
   "metadata": {},
   "source": [
    "An auto-populating function is provided that \n",
    "\n",
    "1. Iterates through a folder `save_dir` containing subfolders `cond_data_folder_title` with paired data `boreholes.pt` and `true_model.pt` containing the boreholes extracted from the ground truth geological model.\n",
    "2. Creates the conditional data for the inverse problem that includes surface, air, and boreholes from `boreholes.pt` and `true_model.pt`\n",
    "3. Runs the inference routine on the data to produce `n_samples_each` for each set of conditional data\n",
    "4. Saves the solutions in the same subfolder with `sample_title_000.pt` naming convention\n",
    "\n",
    "The script below will sample 9 conditional reconstructions for each pair of boreholes with true model. (The true model is only used to get surface and air data, subsurface is not used in the inference)\n",
    "\n",
    "The sample time is long, so precomputed inference results available for demonstration of ensemble analysis below. To run the inference locally, set `USE_PRECOMPUTED_INFERENCE_RESULTS = False` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc6a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRECOMPUTED_INFERENCE_RESULTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba241280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inference_experiments import populate_solutions\n",
    "\n",
    "if not USE_PRECOMPUTED_INFERENCE_RESULTS:\n",
    "    populate_solutions(\n",
    "        save_dir=save_dir,\n",
    "        cond_data_folder_title=cond_data_folder_title,\n",
    "        device=device,\n",
    "        model=flowmatching_model,\n",
    "        n_samples_each=9,\n",
    "        batch_size=1,\n",
    "        sample_title=\"sample\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460116b",
   "metadata": {},
   "source": [
    "### Loading and Viewing Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10058c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_inference_experiments import load_solutions, show_solutions\n",
    "\n",
    "if not USE_PRECOMPUTED_INFERENCE_RESULTS:\n",
    "    # Same folder as the stored conditional data\n",
    "    sample_number = 0\n",
    "    samples_dir = os.path.join(save_dir, f\"{cond_data_folder_title}_{sample_number}\")\n",
    "    print(\"Loading from:\", samples_dir)\n",
    "    # Autoparse the true_model.pt, boreholes.pt, and any solutions\n",
    "    geomodel, boreholes = load_model_and_boreholes(samples_dir)\n",
    "    solutions = load_solutions(samples_dir, sample_title=\"sample\")\n",
    "    show_model_and_boreholes(geomodel, boreholes)\n",
    "    show_solutions(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb2e28",
   "metadata": {},
   "source": [
    "### Ensemble Analysis\n",
    "Precomputed models and borehole data is provided by decompression of an archive with the model featured in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2301054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tarfile, tempfile, gzip\n",
    "\n",
    "\n",
    "def unpack_pt_archive(archive_path: str, dest_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Decompress a .tar.gz produced by pack_pt_folder into dest_dir,\n",
    "    recreating the original filenames/structure (only .pt files are restored).\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # Stream-decompress gzip to a temp tar for safe random access\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    try:\n",
    "        with gzip.open(archive_path, \"rb\") as gz, open(tmp_path, \"wb\") as out:\n",
    "            while True:\n",
    "                chunk = gz.read(1024 * 1024)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                out.write(chunk)\n",
    "\n",
    "        with tarfile.open(tmp_path, \"r\") as tar:\n",
    "\n",
    "            def is_within_directory(directory, target):\n",
    "                ad = os.path.abspath(directory)\n",
    "                at = os.path.abspath(target)\n",
    "                return os.path.commonprefix([ad, at]) == ad\n",
    "\n",
    "            for member in tar.getmembers():\n",
    "                if not (member.isfile() and member.name.endswith(\".pt\")):\n",
    "                    continue\n",
    "                target_path = os.path.join(dest_dir, member.name)\n",
    "                if not is_within_directory(dest_dir, target_path):\n",
    "                    raise Exception(\"Unsafe path in archive\")\n",
    "                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                with tar.extractfile(member) as src, open(target_path, \"wb\") as dst:\n",
    "                    dst.write(src.read())\n",
    "    finally:\n",
    "        try:\n",
    "            os.unlink(tmp_path)\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf26df3",
   "metadata": {},
   "source": [
    "Decompress `boreholes.pt`, `true_model.pt`, and solutions into a samples directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145d861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored to: /home/sghys/projects/flowtrain_stochastic_interpolation/project/geodata-3d-conditional/samples/jupyter-demo/paper_cond_gen_0\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "rel = \"samples/jupyter-demo/paper_cond_gen_0\"\n",
    "samples_dir = os.path.join(root, rel)\n",
    "archive_path = os.path.join(root, \"dikes_ptpack.tar.gz\")\n",
    "unpack_pt_archive(archive_path, samples_dir)\n",
    "print(\"Restored to:\", samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050986b9",
   "metadata": {},
   "source": [
    "Verify the data loaded and displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3afe5e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e02af847ae94161aebb114ee640b10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36623/index.html?ui=P_0x7d484de739b0_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1d6198cffd40a78fc1fa18e19e6a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36623/index.html?ui=P_0x7d484e2fa9f0_2&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_number = 0\n",
    "geomodel, boreholes = load_model_and_boreholes(samples_dir, device=\"cpu\")\n",
    "solutions = load_solutions(samples_dir, sample_title=\"sample\", device=\"cpu\")\n",
    "show_model_and_boreholes(geomodel, boreholes)\n",
    "# Limit to 10 solutions for display\n",
    "show_solutions(solutions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e45a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_probabilities(solutions: torch.Tensor, num_categories: int = 15) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute per-voxel class probabilities over a batch.\n",
    "    Input:  [B, X, Y, Z] integer categories (may include -1)\n",
    "    Output: [C, X, Y, Z] float probabilities\n",
    "    \"\"\"\n",
    "    assert solutions.dim() == 4\n",
    "    B, X, Y, Z = solutions.shape\n",
    "    device = solutions.device\n",
    "\n",
    "    # Handle negative indices (-1 for \"air\")\n",
    "    if solutions.min().item() < 0:\n",
    "        solutions = solutions + 1  # shift to 0..C-1\n",
    "\n",
    "    solutions = solutions.to(torch.long)\n",
    "\n",
    "    # Accumulator for per-class voxel counts\n",
    "    accumulator = torch.zeros(num_categories, X, Y, Z, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Accumulate one-hot for each sample\n",
    "    for b in range(B):\n",
    "        one_hot = torch.nn.functional.one_hot(solutions[b], num_classes=num_categories)  # [X, Y, Z, C]\n",
    "        one_hot = one_hot.permute(3, 0, 1, 2).float()                 # [C, X, Y, Z]\n",
    "        accumulator += one_hot\n",
    "\n",
    "    # Normalize by total samples\n",
    "    probabilities = accumulator / B\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "solution_probabilistic = vote_probabilities(solutions, num_categories=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535270f1",
   "metadata": {},
   "source": [
    "## Display Probabilistic Results\n",
    "The probability for one of the dike categories is compared against the true model and the conditional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c67d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbba51d6ac146919348db865e5aad3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36623/index.html?ui=P_0x7d483cb153d0_3&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba813e5a3b341ab86744048d92adc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36623/index.html?ui=P_0x7d486e937620_4&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_voxel_grid_from_tensor(\n",
    "    data, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=None\n",
    "):\n",
    "    \"\"\" \"\"\"\n",
    "    assert data.ndim == 3, \"Data must be 3D\"\n",
    "    dims = data.shape\n",
    "\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu().numpy()\n",
    "\n",
    "    # Create a padded grid with n+1 nodes and node spacing equal to model sample spacing\n",
    "    dimensions = tuple(x + 1 for x in dims)\n",
    "    spacing = tuple((x[1] - x[0]) / (r - 1) for x, r in zip(bounds, dims))\n",
    "    # pad origin with a half cell size to center the grid\n",
    "    origin = tuple(x[0] - cs / 2 for x, cs in zip(bounds, spacing))\n",
    "\n",
    "    # Create a structured grid with n+1 nodes in each dimension forming n^3 cells\n",
    "    grid = pv.ImageData(\n",
    "        dimensions=dimensions,\n",
    "        spacing=spacing,\n",
    "        origin=origin,\n",
    "    )\n",
    "    # Necessary to reshape data vector in Fortran order to match the grid\n",
    "    grid[\"values\"] = data.flatten(order=\"F\")\n",
    "    grid = grid.threshold(threshold, all_scalars=True)\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "geomodel.squeeze_().squeeze_()\n",
    "true_grid = get_voxel_grid_from_tensor(\n",
    "    geomodel, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=-0.5\n",
    ")\n",
    "boreholes.squeeze_().squeeze_()\n",
    "borehole_grid = get_voxel_grid_from_tensor(\n",
    "    boreholes, bounds=((-1920, 1920), (-1920, 1920), (-1920, 1920)), threshold=-0.5\n",
    ")\n",
    "\n",
    "# Index into the category of choice\n",
    "DIKE_VALS = [6, 7, 8]\n",
    "dike_indices = [x + 1 for x in DIKE_VALS]  # Account for earlier shift\n",
    "dike_probs = solution_probabilistic[dike_indices, :, :, :]  # Slice out only dike layers\n",
    "\n",
    "# Set to spatial coords\n",
    "x = np.linspace(-1920, 1920, 64)\n",
    "y = np.linspace(-1920, 1920, 64)\n",
    "z = np.linspace(-1920, 1920, 64)\n",
    "x, y, z = np.meshgrid(x, y, z, indexing=\"ij\")  # Ensure correct shape order\n",
    "mesh = pv.StructuredGrid(x, y, z)\n",
    "\n",
    "# Extract the first channel\n",
    "dike1_data = dike_probs[1].detach().cpu().numpy().ravel(order=\"F\")\n",
    "mesh[\"dike1\"] = dike1_data  # Assign to mesh\n",
    "\n",
    "dike2_data = dike_probs[2].detach().cpu().numpy().ravel(order=\"F\")\n",
    "mesh[\"dike2\"] = dike2_data  # Assign to mesh\n",
    "\n",
    "dike1_true = true_grid.copy()\n",
    "dike1_true[\"values\"] = np.where(\n",
    "    ~np.isin(dike1_true[\"values\"], DIKE_VALS[1]), -1, dike1_true[\"values\"]\n",
    ")\n",
    "dike1_true = dike1_true.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike2_true = true_grid.copy()\n",
    "dike2_true[\"values\"] = np.where(\n",
    "    ~np.isin(dike2_true[\"values\"], DIKE_VALS[2]), -1, dike2_true[\"values\"]\n",
    ")\n",
    "dike2_true = dike2_true.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike1_samples = borehole_grid.copy()\n",
    "dike1_samples[\"values\"] = np.where(\n",
    "    ~np.isin(dike1_samples[\"values\"], DIKE_VALS[1]), -1, dike1_samples[\"values\"]\n",
    ")\n",
    "dike1_samples = dike1_samples.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "dike2_samples = borehole_grid.copy()\n",
    "dike2_samples[\"values\"] = np.where(\n",
    "    ~np.isin(dike2_samples[\"values\"], DIKE_VALS[2]), -1, dike2_samples[\"values\"]\n",
    ")\n",
    "dike2_samples = dike2_samples.threshold(-0.5, all_scalars=True)\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(\n",
    "    dike1_true,\n",
    "    color=\"orange\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=0.3,\n",
    ")\n",
    "p.add_mesh(\n",
    "    dike1_samples,\n",
    "    scalars=None,\n",
    "    color=\"red\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=1.0,\n",
    ")\n",
    "p.add_title(\"Dike 1 True with Borehole Samples\")\n",
    "p.show()\n",
    "\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(\n",
    "    dike1_samples,\n",
    "    scalars=None,\n",
    "    color=\"red\",\n",
    "    show_scalar_bar=False,\n",
    "    interpolate_before_map=False,\n",
    "    opacity=1.0,\n",
    ")\n",
    "\n",
    "contour = mesh.contour([0.05, 0.3, 0.6, 0.9], scalars=f\"dike1\")\n",
    "p.add_mesh(\n",
    "    contour,\n",
    "    opacity=0.3,\n",
    "    cmap=\"Wistia\",\n",
    "    show_scalar_bar=False,\n",
    ")\n",
    "\n",
    "p.add_scalar_bar(\n",
    "    f\"Probability Contour\",\n",
    "    vertical=False,\n",
    "    title_font_size=24,\n",
    "    label_font_size=24,\n",
    "    fmt=\"%.2f\",\n",
    "    n_labels=4,\n",
    ")\n",
    "\n",
    "p.add_title(\"Dike 1 Probabilistic Surfaces with Borehole Samples\")\n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
